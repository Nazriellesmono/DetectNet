{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Data Processing"
      ],
      "metadata": {
        "id": "BnGy_P9xwZsB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3S6CIfAhlbNX",
        "outputId": "7f7b921a-2f98-4d0f-d9d9-c40ce5cc880f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of detected anomalies: 9989\n",
            "Percentage of anomalies: 10.00%\n",
            "\n",
            "Sample of detected anomalies:\n",
            "              timestamp           src_ip           dst_ip  packet_count  \\\n",
            "1   2025-01-01 07:14:22  184.214.112.115    151.142.3.195          6574   \n",
            "8   2025-01-01 13:53:39  153.239.128.249     142.5.58.175          2827   \n",
            "20  2025-01-01 07:45:38   130.135.67.239     90.35.125.95          9900   \n",
            "34  2025-01-01 09:04:22    235.62.233.35  206.237.162.244          9270   \n",
            "38  2025-01-01 12:48:25   77.199.214.138   192.112.249.57          7371   \n",
            "\n",
            "    byte_count  duration  \n",
            "1      5661907  1.639247  \n",
            "8      5924115  4.404176  \n",
            "20     6075395  6.155610  \n",
            "34     8159521  8.322635  \n",
            "38     6639317  6.721849  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Load the raw dataset\n",
        "df = pd.read_csv('raw_network_anomaly_dataset.csv')\n",
        "\n",
        "# Define feature columns\n",
        "numerical_features = ['packet_count', 'byte_count', 'duration']\n",
        "categorical_features = ['protocol', 'service']\n",
        "ip_features = ['src_ip', 'dst_ip']  # IPs will be processed separately\n",
        "port_features = ['src_port', 'dst_port']\n",
        "timestamp_feature = ['timestamp']\n",
        "\n",
        "# Function to extract the last octet of IP addresses as a numerical feature\n",
        "def extract_ip_octet(ip_series):\n",
        "    return ip_series.apply(lambda x: int(x.split('.')[-1]))\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_features),\n",
        "        ('cat', OneHotEncoder(sparse_output=False, handle_unknown='ignore'), categorical_features),\n",
        "        ('port', StandardScaler(), port_features),\n",
        "        ('ip_src', StandardScaler(), ['src_ip_octet']),\n",
        "        ('ip_dst', StandardScaler(), ['dst_ip_octet'])\n",
        "    ])\n",
        "\n",
        "# Prepare data for anomaly detection\n",
        "X = df[numerical_features + categorical_features + port_features + ip_features].copy()\n",
        "X['src_ip_octet'] = extract_ip_octet(df['src_ip'])\n",
        "X['dst_ip_octet'] = extract_ip_octet(df['dst_ip'])\n",
        "\n",
        "# Create pipeline with preprocessing and Isolation Forest\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('isolation_forest', IsolationForest(contamination=0.1, random_state=42))\n",
        "])\n",
        "\n",
        "# Fit and predict anomalies\n",
        "pipeline.fit(X)\n",
        "anomaly_labels = pipeline.predict(X)  # -1 for anomalies, 1 for normal\n",
        "\n",
        "# Add anomaly labels to the dataset\n",
        "df['is_anomaly'] = np.where(anomaly_labels == -1, 1, 0)\n",
        "\n",
        "# Save the dataset with predicted anomaly labels\n",
        "df.to_csv('labeled_network_anomaly_dataset.csv', index=False)\n",
        "\n",
        "# Print summary\n",
        "print(f\"Number of detected anomalies: {df['is_anomaly'].sum()}\")\n",
        "print(f\"Percentage of anomalies: {df['is_anomaly'].mean() * 100:.2f}%\")\n",
        "\n",
        "# Display sample of anomalies\n",
        "print(\"\\nSample of detected anomalies:\")\n",
        "print(df[df['is_anomaly'] == 1][['timestamp', 'src_ip', 'dst_ip', 'packet_count', 'byte_count', 'duration']].head())"
      ]
    }
  ]
}